{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2347441,"sourceType":"datasetVersion","datasetId":1417162}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Movie Genre Prediction by Naive Bayes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries #","metadata":{}},{"cell_type":"code","source":"import numpy as np  # NumPy: Numerical computing library for arrays and matrices.\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer\n# Import necessary modules\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\n# Import the necessary module\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:51:15.268884Z","iopub.execute_input":"2024-02-12T15:51:15.269386Z","iopub.status.idle":"2024-02-12T15:51:15.279760Z","shell.execute_reply.started":"2024-02-12T15:51:15.269351Z","shell.execute_reply":"2024-02-12T15:51:15.277425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Train Data #","metadata":{}},{"cell_type":"code","source":"# Load the training data\ntrain_path = \"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt\"\ntrain_data = pd.read_csv(train_path, sep=':::', names=['Title', 'Genre', 'Description'], engine='python')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:51:21.513616Z","iopub.execute_input":"2024-02-12T15:51:21.514201Z","iopub.status.idle":"2024-02-12T15:51:21.939050Z","shell.execute_reply.started":"2024-02-12T15:51:21.514161Z","shell.execute_reply":"2024-02-12T15:51:21.937269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.describe())","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:51:26.029418Z","iopub.execute_input":"2024-02-12T15:51:26.029882Z","iopub.status.idle":"2024-02-12T15:51:26.187227Z","shell.execute_reply.started":"2024-02-12T15:51:26.029847Z","shell.execute_reply":"2024-02-12T15:51:26.185067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.info())","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:51:33.299672Z","iopub.execute_input":"2024-02-12T15:51:33.300553Z","iopub.status.idle":"2024-02-12T15:51:33.336023Z","shell.execute_reply.started":"2024-02-12T15:51:33.300508Z","shell.execute_reply":"2024-02-12T15:51:33.333543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:52:05.003879Z","iopub.execute_input":"2024-02-12T15:52:05.004279Z","iopub.status.idle":"2024-02-12T15:52:05.034471Z","shell.execute_reply.started":"2024-02-12T15:52:05.004252Z","shell.execute_reply":"2024-02-12T15:52:05.032277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Test Data #","metadata":{}},{"cell_type":"code","source":"# Load the test data\ntest_path = \"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data.txt\"\ntest_data = pd.read_csv(test_path, sep=':::', names=['Id', 'Title', 'Description'], engine='python')\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:51:44.975252Z","iopub.execute_input":"2024-02-12T15:51:44.975671Z","iopub.status.idle":"2024-02-12T15:51:45.549671Z","shell.execute_reply.started":"2024-02-12T15:51:44.975640Z","shell.execute_reply":"2024-02-12T15:51:45.547776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Data #","metadata":{}},{"cell_type":"code","source":"#Count each genre value\ntrain_data.Genre.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:52:23.917541Z","iopub.execute_input":"2024-02-12T15:52:23.918036Z","iopub.status.idle":"2024-02-12T15:52:23.929506Z","shell.execute_reply.started":"2024-02-12T15:52:23.917997Z","shell.execute_reply":"2024-02-12T15:52:23.928497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot count plot\nplt.figure(figsize=(12,8))\ncounts = train_data.Genre.value_counts()\nsns.barplot(x=counts.index, y=counts, color='blue')\nplt.xlabel('Genre' ,fontsize=14, fontweight='bold')\nplt.ylabel('Count', fontsize=14, fontweight='bold')\nplt.title('Distribution of Genres', fontsize=16, fontweight='bold')\nplt.xticks(rotation=90, fontsize=14, fontweight='bold');\n\n# Plot the distribution of genres in the training data\nplt.figure(figsize=(14, 7))\nsns.countplot(data=train_data, y='Genre', order=train_data['Genre'].value_counts().index, palette='viridis')\nplt.xlabel('Count', fontsize=14, fontweight='bold')\nplt.ylabel('Genre', fontsize=14, fontweight='bold')\n\n# Plot the distribution of genres using a bar plot\nplt.figure(figsize=(14, 7))\ncounts = train_data['Genre'].value_counts()\nsns.barplot(x=counts.index, y=counts, palette='viridis')\nplt.xlabel('Genre', fontsize=14, fontweight='bold')\nplt.ylabel('Count', fontsize=14, fontweight='bold')\nplt.title('Distribution of Genres', fontsize=16, fontweight='bold')\nplt.xticks(rotation=90, fontsize=14, fontweight='bold')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:52:26.715373Z","iopub.execute_input":"2024-02-12T15:52:26.715803Z","iopub.status.idle":"2024-02-12T15:52:27.986005Z","shell.execute_reply.started":"2024-02-12T15:52:26.715771Z","shell.execute_reply":"2024-02-12T15:52:27.984400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning & PreprocessingÂ¶\n","metadata":{}},{"cell_type":"code","source":"train_data.info()\n#Finda any null value\ntrain_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:52:35.601222Z","iopub.execute_input":"2024-02-12T15:52:35.601705Z","iopub.status.idle":"2024-02-12T15:52:35.660346Z","shell.execute_reply.started":"2024-02-12T15:52:35.601671Z","shell.execute_reply":"2024-02-12T15:52:35.658925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the stemmer and stop words\nstemmer = LancasterStemmer()\nstop_words = set(stopwords.words('english'))\n\n# Define the clean_text function\ndef clean_text(text):\n    text = text.lower()  # Lowercase all characters\n    text = re.sub(r'@\\S+', '', text)  # Remove Twitter handles\n    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n    text = re.sub(r'pic.\\S+', '', text)\n    text = re.sub(r\"[^a-zA-Z+']\", ' ', text)  # Keep only characters\n    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text + ' ')  # Keep words with length > 1 only\n    text = \"\".join([i for i in text if i not in string.punctuation])\n    words = nltk.word_tokenize(text)\n    stopwords = nltk.corpus.stopwords.words('english')  # Remove stopwords\n    text = \" \".join([i for i in words if i not in stopwords and len(i) > 2])\n    text = re.sub(\"\\s[\\s]+\", \" \", text).strip()  # Remove repeated/leading/trailing spaces\n    return text\n\n# Apply the clean_text function to the 'Description' column in the training and test data\ntrain_data['Text_cleaning'] = train_data['Description'].apply(clean_text)\ntest_data['Text_cleaning'] = test_data['Description'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:52:49.818349Z","iopub.execute_input":"2024-02-12T15:52:49.818752Z","iopub.status.idle":"2024-02-12T15:54:27.611377Z","shell.execute_reply.started":"2024-02-12T15:52:49.818726Z","shell.execute_reply":"2024-02-12T15:54:27.608816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Droping the redundant data\nprint(\"shape before drop nulls\",train_data.shape)\ntrain_data = train_data.drop_duplicates()\nprint(\"shape after drop nulls\",train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:55:06.195586Z","iopub.execute_input":"2024-02-12T15:55:06.196184Z","iopub.status.idle":"2024-02-12T15:55:06.409867Z","shell.execute_reply.started":"2024-02-12T15:55:06.196143Z","shell.execute_reply":"2024-02-12T15:55:06.408129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the length of cleaned text\ntrain_data['length_Text_cleaning'] = train_data['Text_cleaning'].apply(len)\n# Visualize the distribution of text lengths\nplt.figure(figsize=(8, 7))\nsns.histplot(data=train_data, x='length_Text_cleaning', bins=20, kde=True, color='blue')\nplt.xlabel('Length', fontsize=14, fontweight='bold')\nplt.ylabel('Frequency', fontsize=14, fontweight='bold')\nplt.title('Distribution of Lengths', fontsize=16, fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:55:45.908502Z","iopub.execute_input":"2024-02-12T15:55:45.909013Z","iopub.status.idle":"2024-02-12T15:55:46.482635Z","shell.execute_reply.started":"2024-02-12T15:55:45.908973Z","shell.execute_reply":"2024-02-12T15:55:46.481092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create histograms to visualize the distribution of text lengths before and after cleaning\n\n# Set up the figure with two subplots\nplt.figure(figsize=(12, 6))\n\n# Subplot 1: Original text length distribution\nplt.subplot(1, 2, 1)\noriginal_lengths = train_data['Description'].apply(len)\nplt.hist(original_lengths, bins=range(0, max(original_lengths) + 100, 100), color='blue', alpha=0.7)\nplt.title('Original Text Length')\nplt.xlabel('Text Length')\nplt.ylabel('Frequency')\n\n# Subplot 2: Cleaned text length distribution\nplt.subplot(1, 2, 2)\ncleaned_lengths = train_data['Text_cleaning'].apply(len)\nplt.hist(cleaned_lengths, bins=range(0, max(cleaned_lengths) + 100, 100), color='green', alpha=0.7)\nplt.title('Cleaned Text Length')\nplt.xlabel('Text Length')\nplt.ylabel('Frequency')\n\n# Adjust layout and display the plots\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:58:26.838724Z","iopub.execute_input":"2024-02-12T15:58:26.839309Z","iopub.status.idle":"2024-02-12T15:58:27.887753Z","shell.execute_reply.started":"2024-02-12T15:58:26.839251Z","shell.execute_reply":"2024-02-12T15:58:27.886830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Vectorization (TF-IDF)","metadata":{}},{"cell_type":"code","source":"# Initialize the TF-IDF vectorizer\ntfidf_vectorizer = TfidfVectorizer()\n\n# Fit and transform the training data\nX_train = tfidf_vectorizer.fit_transform(train_data['Text_cleaning'])\n\n# Transform the test data\nX_test = tfidf_vectorizer.transform(test_data['Text_cleaning'])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-12T15:58:31.160744Z","iopub.execute_input":"2024-02-12T15:58:31.161235Z","iopub.status.idle":"2024-02-12T15:58:38.188555Z","shell.execute_reply.started":"2024-02-12T15:58:31.161199Z","shell.execute_reply":"2024-02-12T15:58:38.186022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Split Data and Train a Model (Naive Bayes) #","metadata":{}},{"cell_type":"code","source":"# Split the data into training and validation sets\nX = X_train\ny = train_data['Genre']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train a Multinomial Naive Bayes classifier\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)\n\n# Make predictions on the validation set\ny_pred = classifier.predict(X_val)\n\n# Evaluate the performance of the model\naccuracy = accuracy_score(y_val, y_pred)\nprint(\"Validation Accuracy:\", accuracy)\nprint(classification_report(y_val, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-12T16:02:05.608492Z","iopub.execute_input":"2024-02-12T16:02:05.609300Z","iopub.status.idle":"2024-02-12T16:02:06.203437Z","shell.execute_reply.started":"2024-02-12T16:02:05.609205Z","shell.execute_reply":"2024-02-12T16:02:06.201551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # Make Predictions on the Test Data #","metadata":{}},{"cell_type":"code","source":"# Use the trained model to make predictions on the test data\nX_test_predictions = classifier.predict(X_test)\ntest_data['Predicted_Genre'] = X_test_predictions","metadata":{"execution":{"iopub.status.busy":"2024-02-12T16:02:18.035432Z","iopub.execute_input":"2024-02-12T16:02:18.035814Z","iopub.status.idle":"2024-02-12T16:02:18.254081Z","shell.execute_reply.started":"2024-02-12T16:02:18.035789Z","shell.execute_reply":"2024-02-12T16:02:18.250368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the test_data DataFrame with predicted genres to a CSV file\ntest_data.to_csv('predicted_genres.csv', index=False)\n\n# Display the 'test_data' DataFrame with predicted genres\nprint(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T16:02:20.690591Z","iopub.execute_input":"2024-02-12T16:02:20.691119Z","iopub.status.idle":"2024-02-12T16:02:21.850844Z","shell.execute_reply.started":"2024-02-12T16:02:20.691079Z","shell.execute_reply":"2024-02-12T16:02:21.849666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}